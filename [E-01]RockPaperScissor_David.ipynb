{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Exp-1] 노드 1-7. 프로젝트: 가위바위보 분류기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터를 준비하자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 우리는 노트북 전면 카메라를 활용하여 가위, 바위, 보 이미지 각 100장을 만들어 볼거예요. 그런데 300장을 어느 세월에 만들까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://teachablemachine.withgoogle.com/  ##Teachable machine 사이트에서 손쉽게 사진 캡쳐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기 + Resize 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) 숫자 손글씨의 경우 이미지 크기가 28x28 이었기 때문에, 우리의 가위, 바위, 보 이미지도 28x28로 만들어야 합니다. 이를 위해서는 PIL 라이브러리를 사용해볼 거예요. 그러려면 먼저 라이브러리를 불러와야 겠죠?\n",
    "혹시 PIL 라이브러리가 없는 경우 필요한 패키지를 설치해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages (8.1.0)\n",
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "import numpy as np\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 가위 이미지를 불러와서 28x28 사이즈로 변경할 겁니다. 아래 코드를 실행해보세요. 이미지의 크기가 28x28 로 바뀌었나요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/rock_scissor_paper/train_dataset_total/data_3300/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/rock_scissor_paper/train_dataset_total/data_3300/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자 그러면, 바위 이미지도 28x28 로 만들어 볼까요? 아래 빈 칸에 코드를 작성하고, 실행해보세요. 바위 이미지가 모두 28x28로 바뀌어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/rock_scissor_paper/train_dataset_total/data_3300/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/rock_scissor_paper/train_dataset_total/data_3300/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/rock_scissor_paper/train_dataset_total/data_3300/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/rock_scissor_paper/train_dataset_total/data_3300/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) 숫자 손글씨 인식기는 mnist.load_data() 라는 함수로 데이터를 읽었던 것 기억하시죠? 여러분들이 아직 코딩에 익숙하지 않을 수 있으므로, 가위, 바위, 보 데이터를 읽을 수 있는 load_data() 함수를 만들어 드릴 거예요. 이 코드를 활용하면 임의의 사진 데이터(ex. 귤이 잘 익었나, 안 익었나? 웃는 얼굴인가, 우는 얼굴인가, 평범한 표정의 얼굴인가? 등)에 적용하실 수 있을 겁니다.\n",
    "\n",
    "load_data() 함수는 입력으로 이미지가 있는 폴더 위치를 받습니다. 여기서는 rock_scissor_paper 폴더 위치를 적어주면 됩니다. 그리고, 숫자 손글씨는 0~9 까지의 클래스가 있었던 것 기억하시죠? 가위바위보의 경우 3개의 클래스 즉, 가위: 0, 바위: 1, 보: 2 로 라벨링이 될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 9000 입니다.\n",
      "x_train shape: (9300, 28, 28, 3)\n",
      "y_train shape: (9300,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=9300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/rock_scissor_paper/train_dataset_total/data_3300\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 번 이미지를 불러 볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자 이제 데이터의 준비가 끝났습니다. 이제 여러분들이 가위바위보를 인식하는 딥러닝 네트워크를 설계해 볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                51232     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 70,723\n",
      "Trainable params: 70,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 설계가 되었다면, 이제 학습을 시켜봅시다. 아마도 여러분들의 데이터는 거의 비슷비슷할 것이기 때문에 accuracy가 꽤 높게 나올 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "291/291 [==============================] - 4s 12ms/step - loss: 0.9598 - accuracy: 0.4939\n",
      "Epoch 2/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.6393 - accuracy: 0.7220\n",
      "Epoch 3/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8377\n",
      "Epoch 4/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.2971 - accuracy: 0.8901\n",
      "Epoch 5/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.9331\n",
      "Epoch 6/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.1332 - accuracy: 0.9573\n",
      "Epoch 7/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.0995 - accuracy: 0.9705\n",
      "Epoch 8/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9806\n",
      "Epoch 9/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.0629 - accuracy: 0.9823\n",
      "Epoch 10/10\n",
      "291/291 [==============================] - 0s 1ms/step - loss: 0.0372 - accuracy: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0ee5b8eb90>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 얼마나 잘 만들었는지 확인하기(테스트)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러분들은 300장의 가위바위보 이미지를 만들어 모두 학습에 사용했습니다. 그러므로 테스트 데이터가 없죠. 옆 친구의 이미지 데이터 300장을 받아오세요. 그리고 그것을 테스트 데이터로 하여 test accuracy를 측정해보세요.\n",
    "\n",
    "우선 테스트용 데이터인 x_test, y_test를 만들어 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/rock_scissor_paper/paper\n",
      "보 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "# 테스트 이미지를 한꺼번에..\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/rock_scissor_paper\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트용 데이터가 준비되었으니, 위에서 훈련시킨 model을 사용하여 test_accuracy를 측정해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.0197 - accuracy: 1.0000\n",
      "test_loss: 0.01968994177877903 \n",
      "test_accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 더 좋은 네트워크 만들어보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시험용 데이터(x_test)에 대한 인식률(test accuracy)이 train accuracy보다 많이 낮게 나오지는 않았나요?\n",
    "만약 그렇다면 그 이유는 무엇일까요? MNIST 손글씨 데이터 때처럼 test accuracy가 train accuracy에 근접하도록 개선 방법을 찾아 봅시다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫 개발의 소회"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뭔가 이상하다... accuracy가 1이다..\n",
    "사실상 처음으로 만들어 보는 머신러닝 프로그램이고 목적에 맞게 코딩이 되었는지 쉽게 이해 할 수 있는 주피터 노트북에 놀라웠다.\n",
    "하지만 각 단계의 함수들..   내부는 어떤 구조로 이루어 졌는지 더욱 공부 하고 싶은 충동이....\n",
    "일단 다음 단계는 지금 작성한 코드를 단편적으로 외워 보기로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
