{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bronze-cabinet",
   "metadata": {},
   "source": [
    "# E12 인공지능으로 세상에 없던 새로운 패션 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-milwaukee",
   "metadata": {},
   "source": [
    "## ?? 프로젝트 목표 : GAN 이해하고 생성 모델링을 경험 하자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-discretion",
   "metadata": {},
   "source": [
    "## STEP 0. 작업환경 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mysterious-fleet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import PIL\n",
    "import imageio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"tensorflow\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "liquid-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_x, _), (test_x, _) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-smith",
   "metadata": {},
   "source": [
    "## STEP 1. 데이터셋 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR-10 데이터셋도 tf.keras 안에 있는 datasets에 포함되어 있어서, 아래와 같이 손쉽게 데이터셋을 구성할 수 있습니다.\n",
    "\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "\n",
    "(train_x, _), (test_x, _) = cifar10.load_data()\n",
    "\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-cookie",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-sheet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-circle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-digest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "coastal-thousand",
   "metadata": {},
   "source": [
    "## STEP 2. 생성자 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    (32, 32, 3)의 shape를 가진 이미지를 생성하는 생성자 모델 구현 함수를 작성해 봅시다.\n",
    "    noise = tf.random.normal([1, 100])로 생성된 랜덤 노이즈를 입력으로 하여 방금 구현한 생성자로 랜덤 이미지를 생성해 봅시다.\n",
    "    생성된 랜덤 이미지가 생성자 출력 규격에 잘 맞는지 확인해 봅시다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "\n",
    "    # Start\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # First: Dense layer\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # Second: Reshape layer\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "\n",
    "    # Third: Conv2DTranspose layer\n",
    "    model.add(layers.Conv2DTranspose(128, kernel_size=(5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # Fourth: Conv2DTranspose layer\n",
    "    model.add(layers.Conv2DTranspose(64, kernel_size=(5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # Fifth: Conv2DTranspose layer\n",
    "    model.add(layers.Conv2DTranspose(1, kernel_size=(5, 5), strides=(2, 2), padding='same', use_bias=False, \\\n",
    "                                     activation='tanh'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-score",
   "metadata": {},
   "source": [
    "## STEP 3. 판별자 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    (32, 32, 3)의 이미지를 입력으로 받아 1dim을 판별결과를 출력하는 판별자 모델 구현 함수를 작성해 봅시다.\n",
    "    위 STEP 2에서 생성한 랜덤 이미지를 판별자 모델이 판별한 결과값을 확인해 봅시다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-contest",
   "metadata": {},
   "source": [
    "## STEP 4. 손실함수와 최적화 함수 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    생성자와 판별자의 손실함수(loss)를 구현해 봅시다.\n",
    "    판별자의 출력값을 가지고 실제/생성(real/fake) 이미지 판별 정확도(accuracy)를 계산하는 함수를 구현해 봅시다.\n",
    "    생성자와 판별자를 최적화하는 optimizer를 정의합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-rendering",
   "metadata": {},
   "source": [
    "## STEP 5. 훈련과정 상세 기능 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    1개 미니배치의 훈련 과정을 처리하는 train_step() 함수를 구현해 봅시다.\n",
    "    16개의 고정된 seed를 입력으로 하여 훈련 과정 동안 생성한 이미지를 시각화하는 generate_and_save_images() 함수를 구현해 봅시다.\n",
    "    훈련 epoch마다 생성자/판별자의 loss 및 판별자의 실제/생성(real/fake) 이미지 판별 accuracy 히스토리(history)를 그래프로 시각화하는 draw_train_history() 함수를 구현해 봅시다.\n",
    "    training_checkpoints 디렉토리에 몇 epoch마다 모델을 저장하는 checkpoint 모듈을 설정해 봅시다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-commitment",
   "metadata": {},
   "source": [
    "## STEP 6. 학습 과정 진행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = os.getenv('HOME')+'/dcgan_newimage/cifar10/training_checkpoints'\n",
    "\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "checkpoint.restore(latest)\n",
    "\n",
    "generator = checkpoint.generator\n",
    "discriminator = checkpoint.discriminator\n",
    "\n",
    "# 로드한 모델이 정상적으로 이미지를 생성하는지 확인해 봅니다. \n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "np_generated = generated_image.numpy()\n",
    "np_generated = (np_generated * 127.5) + 127.5   # reverse of normalization\n",
    "np_generated = np_generated.astype(int)\n",
    "plt.imshow(np_generated[0])\n",
    "plt.show()  # 정상적으로 모델이 로드되었다면 랜덤 이미지가 아니라 CIFAR-10 이미지가 그려질 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-saturday",
   "metadata": {},
   "source": [
    "## STEP 7. (optional) GAN 훈련 과정 개선하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    STEP 6을 진행하면서 생성된 샘플 이미지, 학습 과정 그래프 등을 통해 이전 훈련 과정의 문제점을 분석해 봅시다.\n",
    "    모델구조 또는 학습 과정을 개선한 내역과 그 결과(샘플 이미지, 학습 과정 그래프 포함)를 함께 제출합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-entrepreneur",
   "metadata": {},
   "source": [
    "## 루브릭 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-system",
   "metadata": {},
   "source": [
    "1. GAN의 두 모델 구조를 통해 이미지를 성공적으로 생성하였다.\n",
    "\n",
    "   오브젝트 종류를 육안으로 구별할 수 있을 만한 이미지를 생성하였다.\n",
    "   \n",
    "\n",
    "2. 생성 이미지 시각화 및 학습 그래프를 통해 GAN 학습이 바르게 진행되었음을 입증하였다.\n",
    "\n",
    "\tgif를 통해 생성이미지 품질이 서서히 향상되는 것과, fake accuracy가 추세적으로 0.5를 향해 하향하고 있음을 확인하였다.\n",
    "    \n",
    "\n",
    "3. 추가적인 GAN 모델구조 혹은 학습과정 개선 아이디어를 제안하고 이를 적용하였다.\n",
    "\n",
    "\t제출 아이디어를 제출 프로젝트에 반영하고, 그 결과가 아이디어 적용 이전보다 향상되었음을 시각적으로 입증하였다.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-prompt",
   "metadata": {},
   "source": [
    "## 느낀점과 회고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-indie",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
